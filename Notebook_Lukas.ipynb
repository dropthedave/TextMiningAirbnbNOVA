{"cells":[{"cell_type":"markdown","metadata":{"id":"Y-M1169-7Fkt"},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3708,"status":"ok","timestamp":1683476300252,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"06dOl_gNEJQb","outputId":"e940cad8-660a-40fd-8efc-bcc52d5edc54"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\lukas\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\lukas\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\lukas\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package snowball_data to\n","[nltk_data]     C:\\Users\\lukas\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package snowball_data is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\lukas\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n"]}],"source":["# basics\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# preprocessing\n","import re\n","import nltk\n","from nltk.tokenize import word_tokenize \n","from nltk.corpus import stopwords, wordnet\n","from nltk.stem import SnowballStemmer\n","from nltk.stem.wordnet import WordNetLemmatizer\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('snowball_data')\n","nltk.download('averaged_perceptron_tagger')\n","\n","# sentiment analysis (vaderSentiment)\n","try:\n","    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","except:\n","    !pip install vaderSentiment\n","    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","\n","# # pycld2\n","# try:\n","#   import pycld2 as cld2\n","# except:\n","#   !pip install pycld2\n","#   import pycld2 as cld2\n","\n","# # deep_translator\n","# try:\n","#   from deep_translator import GoogleTranslator\n","# except:\n","#   !pip install deep-translator\n","#   from deep_translator import GoogleTranslator\n","\n","# sklearn\n","from sklearn.model_selection import train_test_split, learning_curve\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report, RocCurveDisplay\n","\n","from imblearn.over_sampling import SMOTE"]},{"cell_type":"markdown","metadata":{"id":"mk5tfM-27Fky"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2195,"status":"ok","timestamp":1683476302442,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"2mDQggAH7ehv","outputId":"bac33a80-ea4a-4e3d-89bc-7f9eaf29059e"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# %cd '/content/drive/MyDrive/TextMiningProject'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":68160,"status":"ok","timestamp":1683470790164,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"Kma2qam77Fky"},"outputs":[],"source":["train = pd.read_excel('Data/train.xlsx', index_col='index')\n","train_reviews = pd.read_excel('Data/train_reviews.xlsx', index_col='index')"]},{"cell_type":"markdown","metadata":{"id":"xqFhw_b3ohpN"},"source":["# 1. Exploratory Data Analysis\n","\n","- on whole trainset (maybe train-test split has to be done before exploration)"]},{"cell_type":"markdown","metadata":{"id":"IqVfhupcqkRs"},"source":["## 1.1 train.xlsx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M_DwjhApomC5"},"outputs":[],"source":["# define dataframe variable\n","dataframe = train.copy()\n","dataframe = dataframe.reset_index()\n","\n","# define target feature\n","target_feature = 'unlisted'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1289,"status":"ok","timestamp":1683469254050,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"37ML7cc8p_5w","outputId":"38453cbd-24a5-490a-8746-f96197b23f30"},"outputs":[],"source":["# display head & tail\n","dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1683469254051,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"h19JSim7qEla","outputId":"877bb77d-d761-40bb-ab8f-ce61d7eb2cf2"},"outputs":[],"source":["# data types\n","print('Data Types:', '\\n')\n","dataframe.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1683469254051,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"msLG5vulqRKE","outputId":"8275be72-65bc-4fbe-9323-8feb01e98ba1"},"outputs":[],"source":["# missing values\n","print('Missing Values:', '\\n')\n","pd.concat([dataframe.isnull().sum(), dataframe.eq('').sum()], keys=['Nulls','Empty Strings'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1683469254052,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"gmN1LvMMqUuA","outputId":"9afbc8c7-2edc-4469-c87e-74239dfc7825"},"outputs":[],"source":["# duplicated rows\n","print('Duplicated Rows:', '\\n')\n","dataframe.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1683469254052,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"_dBlN3rpqYx5","outputId":"19a7ce6d-cf28-4019-d255-66569a599048"},"outputs":[],"source":["# descriptive statistics\n","print('Descriptive Statistics:', '\\n')\n","dataframe.describe(include='all').T"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1683469254052,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"yYzwQ0vSrocf","outputId":"c2f04f26-0265-47b8-d780-a6ef288fc405"},"outputs":[],"source":["# check for imbalance\n","# Count the number of instances for each target value\n","target_counts = dataframe[target_feature].value_counts()\n","\n","# Create a pie chart\n","plt.pie(target_counts, labels=target_counts.index, autopct='%1.1f%%')\n","plt.axis('equal')\n","plt.title('Target Imbalance Check')\n","plt.legend(labels=['listed', 'unlisted'])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"cew43zt9qr0u"},"source":["## 1.2 train_reviews.xlsx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FAknBDRgqx-6"},"outputs":[],"source":["# define dataframe variable\n","dataframe = train_reviews.copy()\n","dataframe = dataframe.reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1683469254429,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"Q2dt7knGq5j5","outputId":"135759b3-5b9f-42b5-a4b4-0c77dcfe5c6a"},"outputs":[],"source":["# display head & tail\n","dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1683469254430,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"bxAfkveHrBSn","outputId":"694e3fc6-8135-4624-b501-1a627dcc2261"},"outputs":[],"source":["# data types\n","print('Data Types:', '\\n')\n","dataframe.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683469254430,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"a_zihtl1rB3b","outputId":"bb06179f-bd7d-4ddc-d14f-892d9c95f403"},"outputs":[],"source":["# missing values\n","print('Missing Values:', '\\n')\n","pd.concat([dataframe.isnull().sum(), dataframe.eq('').sum()], keys=['Nulls','Empty Strings'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1683469254430,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"CJ2VLWzPrb7J","outputId":"753cf447-f1bf-4fd4-f1c7-b6e31e0737fb"},"outputs":[],"source":["# duplicated rows\n","print('Duplicated Rows:', '\\n')\n","dataframe.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1887,"status":"ok","timestamp":1683469256298,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"NtE_LddmriGV","outputId":"29774878-48e3-4f09-9532-78a96625984e"},"outputs":[],"source":["# descriptive statistics\n","print('Descriptive Statistics:', '\\n')\n","dataframe.describe(include='all').T"]},{"cell_type":"markdown","metadata":{"id":"6fSUIrfC7Fkz"},"source":["# 2. Preprocessing\n"]},{"cell_type":"markdown","metadata":{"id":"_UTeUgCKDkC3"},"source":["## 2.1 Regex Patterns"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683470790164,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"LvmUJ6zNDkC3"},"outputs":[],"source":["regex_patterns = {\n","    # manually identified patterns\n","    r'_x005f_x000d_':               ' ',\n","    r'_x000d_':                     ' ',\n","    r'm2':                          'squaremeter',\n","    r'sm':                          'squaremeter',\n","    r'sqm':                         'squaremeter',\n","    r'm²':                          'squaremeter',\n","    r'license[ number]+[0-9a-z]+':  ' ',\n","    r'(\\\\b\\\\w)\\\\1+\\\\b':             ' ',\n","\n","    # basic patterns\n","    # remove url\n","    r'http\\S+':                     ' ',\n","    # remove html tags\n","    r'<.*?>':                       ' ',\n","    # remove punctuation\n","    r'[^\\w\\s]':                     ' ',\n","    # remove numbers\n","    r'\\d+':                         ' ',\n","    # remove multiple whitespace\n","    r'\\s+':                         ' ',\n","    # remove newline\n","    r'\\n':                          ' '\n","}"]},{"cell_type":"markdown","metadata":{"id":"vGCR06nSDkC3"},"source":["## 2.2 Preprocessing Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1012,"status":"ok","timestamp":1683470791172,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"lK8IC2WW7Fkz"},"outputs":[],"source":["def text_preprocessing(dataframe):\n","  '''\n","  Preprocessing Pipeline\n","  Input: dataframe\n","  Output: transformed dataframe\n","  '''\n","\n","  stop_words = set(stopwords.words('english'))\n","  lemmatizer = nltk.stem.WordNetLemmatizer()\n","  stemmers = {\n","    'es': nltk.stem.SnowballStemmer('spanish'),\n","    'pt': nltk.stem.SnowballStemmer('portuguese'),\n","    'nl': nltk.stem.SnowballStemmer('dutch'),\n","    'de': nltk.stem.SnowballStemmer('german'),\n","    'it': nltk.stem.SnowballStemmer('italian'),\n","    'da': nltk.stem.SnowballStemmer('danish'),\n","    'nb': nltk.stem.SnowballStemmer('norwegian'),\n","    'fi': nltk.stem.SnowballStemmer('finnish'),\n","    'sv': nltk.stem.SnowballStemmer('swedish')\n","  }\n","\n","  # lowercase non-numeric features \n","  categorical_features = list(dataframe.select_dtypes(exclude = np.number).columns)\n","  for col in categorical_features:\n","    dataframe[col] = dataframe[col].apply(lambda x: x.lower() if type(x) == str else '')\n","    \n","  # drop duplicates\n","  dataframe = dataframe.reset_index()\n","  dataframe = dataframe.drop_duplicates()\n","\n","  # fill empty cells\n","  for col in categorical_features:\n","    dataframe[col] = dataframe[col].fillna('')\n","\n","  # re.sub regex patterns (dictionary defined in the cell above)\n","  for col in categorical_features:\n","    for key, value in regex_patterns.items():\n","      dataframe[col] = dataframe[col].apply(lambda x: re.sub(key,value,x))\n","\n","  # detect language\n","  for col in categorical_features:\n","    new_col = col + '_lang'\n","    dataframe[new_col] = dataframe[col].apply(lambda x: cld2.detect(x)[-1][0][1] if len(x) < 5000 else 'text has more than 5k characters')\n","  \n","  # tokenize and remove stopwords\n","  for col in categorical_features:\n","    dataframe[col] = dataframe[col].apply(lambda x: [word for word in word_tokenize(x) if word not in stop_words])\n","\n","  # part-of-speech tagging (english only)\n","  for col in categorical_features:\n","    lang_col = col + '_lang'\n","    dataframe[col] = dataframe.apply(lambda row: nltk.pos_tag(row[col]) if row[lang_col] == 'en' else row[col], axis=1)\n","    # wordnet mapping\n","    pos_tag_map = {\n","    'J': wordnet.ADJ,\n","    'V': wordnet.VERB,\n","    'N': wordnet.NOUN,\n","    'R': wordnet.ADV\n","    }\n","\n","    dataframe[col] = dataframe.apply(lambda row: [(word, pos_tag_map.get(tag[0])) for word, tag in row[col]] if row[lang_col] == 'en' else row[col], axis=1)\n","  \n","  # lemmatizing (english only)\n","  for col in categorical_features:\n","    lang_col = col + '_lang'\n","    dataframe[col] = dataframe.apply(lambda row: [lemmatizer.lemmatize(word, tag) if tag else word for word, tag in row[col]] if row[lang_col] == 'en' else row[col], axis=1)\n","  \n","  # stemming (non-english contained in the stemmers dictionary)\n","  for col in categorical_features:\n","    lang_col = col + '_lang'\n","    dataframe[col] = dataframe.apply(lambda row: [stemmers.get(row[lang_col]).stem(word) if row[lang_col] in stemmers.keys() else word for word in row[col]] if row[lang_col] != 'en' else row[col], axis=1)\n","\n","  # combine again\n","  for col in categorical_features:\n","    dataframe[col] = dataframe[col].apply(lambda x: ' '.join(x))\n","\n","  return dataframe"]},{"cell_type":"markdown","metadata":{"id":"0Ltd5aUbDkC4"},"source":["## 2.3 Apply Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":115372,"status":"ok","timestamp":1683470906541,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"g4_QuJANtwb5"},"outputs":[],"source":["train_preprocessed = train.copy()\n","train_preprocessed = text_preprocessing(train_preprocessed)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1434027,"status":"ok","timestamp":1683472340556,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"Gkht-0VLu0c0"},"outputs":[],"source":["train_reviews_preprocessed = train_reviews.copy()\n","train_reviews_preprocessed = text_preprocessing(train_reviews_preprocessed)"]},{"cell_type":"markdown","metadata":{"id":"Bt9h3ODfDkC4"},"source":["# 3. Feature Engineering (Sentiment Analysis on Comments)\n","\n","- so far only sentiment analysis for englisch comments"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1683472340557,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"sHpdH-SFDkC4"},"outputs":[],"source":["def sentiment_analysis(dataframe, column='comments', language_column='comments_lang', compound=False):\n","    '''\n","    Sentiment analysis using vaderSentiment\n","    Input: dataframe\n","    Output: dataframe with sentiment column\n","    '''\n","    new_column = column + '_sentiment'\n","    sia = SentimentIntensityAnalyzer()\n","\n","    # return sentiment label with highest score\n","    if compound is False:\n","      dataframe[new_column] = dataframe[column].apply(lambda x: sia.polarity_scores(x))\n","      dataframe[new_column] = dataframe[new_column].apply(lambda x: {key:val for key,val in x.items() if key != 'compound'})\n","      dataframe[new_column] = dataframe[new_column].apply(lambda x: max(x, key=x.get))\n","      # set empty string comments from 'neg' (negative) to 'neu' (neutral)\n","      dataframe[new_column] = ['neu' if y == '' else x for x,y in zip(dataframe[new_column], dataframe[column])]\n","      # exception for comments which are not in english\n","      dataframe[new_column] = ['neu' if y != 'ENGLISH' else x for x,y in zip(dataframe[new_column], dataframe[language_column])]\n","\n","    # compound score is a combined score that ranges from -1 to 1\n","    # higher values indicating more positive sentiment\n","    elif compound is True:\n","      dataframe[new_column] = dataframe[column].apply(lambda x: sia.polarity_scores(x)['compound'])\n","      # exception for comments which are not in english\n","      dataframe[new_column] = [0 if y != 'ENGLISH' else x for x,y in zip(dataframe[new_column], dataframe[language_column])]\n","\n","    return dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":217405,"status":"ok","timestamp":1683472557958,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"otOcRcemDkC4"},"outputs":[],"source":["train_reviews_sentiment = train_reviews_preprocessed.copy()\n","train_reviews_sentiment = sentiment_analysis(train_reviews_sentiment)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":216351,"status":"ok","timestamp":1683472774303,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"UQXXWGAyDkC5"},"outputs":[],"source":["train_reviews_sentiment_compound = train_reviews_preprocessed.copy()\n","train_reviews_sentiment_compound = sentiment_analysis(train_reviews_sentiment_compound, compound=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":18108,"status":"ok","timestamp":1683472792396,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"Uz-1qjnaDkC5"},"outputs":[],"source":["# train_preprocessed.to_csv('Data/train_preprocessed.csv', index=False)\n","# train_reviews_sentiment.to_csv('Data/train_reviews_sentiment.csv', index=False)\n","# train_reviews_sentiment_compound.to_csv('Data/train_reviews_sentiment_compound.csv', index=False)"]},{"cell_type":"markdown","metadata":{"id":"6tyRQu25EJQi"},"source":["# 4. Train-Test Split"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":13978,"status":"ok","timestamp":1683476316416,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"npfV6P3ADkC5"},"outputs":[],"source":["# read in preprocessed data (so preprocessing doesn't have to be done again)\n","# keep_default_na=False to prevent empty strings from being read in as NaN\n","\n","train_preprocessed = pd.read_csv('Data/train_preprocessed.csv', keep_default_na=False)\n","train_reviews_sentiment = pd.read_csv('Data/train_reviews_sentiment.csv', keep_default_na=False)\n","# train_reviews_sentiment_compound = pd.read_csv('Data/train_reviews_sentiment_compound.csv', keep_default_na=False)"]},{"cell_type":"markdown","metadata":{"id":"eP2acGODEJQj"},"source":["## 5.1 Combine Text"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1683476316417,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"X3tgPHaJDkC6"},"outputs":[],"source":["# combine all text for an airbnb and create one BoW per airbnb\n","\n","def combine_text(dataframe1=train_preprocessed, dataframe2=train_reviews_sentiment):\n","    '''\n","    Combine all text for an airbnb\n","    Input: dataframe1 (train_preprocessed), dataframe2 (train_reviews_sentiment)\n","    Output: combined dataframe\n","    Output format: 'unlisted', 'text'\n","    '''\n","    # prepare dataframe1\n","    # combine description and host_about\n","    dataframe1['text'] = [x + ' ' + y for x,y in zip(dataframe1['description'], dataframe1['host_about'])]\n","    # drop description, host_about, description_lang, host_about_lang\n","    dataframe1 = dataframe1.drop(['description', 'host_about', 'description_lang', 'host_about_lang'], axis=1)\n","\n","    # prepare dataframe2\n","    # combine all text comments for an index\n","    aggregated_comments = pd.DataFrame(dataframe2.groupby('index')['comments'].agg(lambda x: ' '.join(x))).reset_index()\n","    # combine all sentiment labels for an index\n","    aggregated_sentiment_label = pd.DataFrame(dataframe2.groupby('index')['comments_sentiment'].agg(lambda x: ' '.join(x))).reset_index()\n","    # add sentiment_labels to aggregated_comments\n","    aggregated_comments['comments'] = [x + ' ' + y for x,y in zip(aggregated_comments['comments'], aggregated_sentiment_label['comments_sentiment'])]\n","    dataframe2 = aggregated_comments\n","\n","    # merge dataframe1 and dataframe2 on index\n","    combined = pd.merge(dataframe1, dataframe2, on='index', how='left')\n","    # fill empty cells for missing comments\n","    combined = combined.fillna('')\n","    # combine all text for an airbnb\n","    combined['text'] = [x + ' ' + y for x,y in zip(combined['text'], combined['comments'])]\n","    # drop comments\n","    combined = combined.drop(['comments'], axis=1)\n","    # set index to 'index' or airbnb id\n","    combined = combined.set_index('index')\n","\n","    return combined"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":4443,"status":"ok","timestamp":1683476320858,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"_E818W8tEJQj","outputId":"fd468c8a-4838-4db0-d45a-16012ab610da"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>unlisted</th>\n","      <th>text</th>\n","    </tr>\n","    <tr>\n","      <th>index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>share mixed room hostel share bathroom locate ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>meu espac fic pert de parqu eduard vii saldanh...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>trafaria house cozy familiar villa facility ne...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       unlisted                                               text\n","index                                                             \n","1             0  share mixed room hostel share bathroom locate ...\n","2             1  meu espac fic pert de parqu eduard vii saldanh...\n","3             1  trafaria house cozy familiar villa facility ne..."]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_preprocessed_to_combine, train_reviews_sentiment_to_combine = train_preprocessed.copy(), train_reviews_sentiment.copy()\n","train_combined = combine_text(train_preprocessed_to_combine, train_reviews_sentiment_to_combine)\n","train_combined.head(3)"]},{"cell_type":"markdown","metadata":{"id":"UgW3LtGkEJQj"},"source":["## 5.2 Train-Test Split"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683476320858,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"zIiGR3wnEJQj"},"outputs":[],"source":["x, y = train_combined['text'], train_combined['unlisted']\n","xtrain, xval, ytrain, yval = train_test_split(x, y, test_size=0.3, stratify=y, random_state=420)"]},{"cell_type":"markdown","metadata":{"id":"sNa7WxNRn3QF"},"source":["# 5. Encoding & SMOTE"]},{"cell_type":"markdown","metadata":{"id":"5TqO0FNxDkC6"},"source":["## 5.2 Bag-of-Words"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MG2ISUYWEJQj"},"outputs":[],"source":["# initialize bow vectorizer\n","bow = CountVectorizer()\n","\n","# transform xtrain and xval\n","xtrain_bow = bow.fit_transform(xtrain).toarray()\n","xval_bow = bow.transform(xval)\n","\n","# SMOTE\n","# initialize SMOTE\n","smote = SMOTE()\n","\n","# fit and resample\n","xtrain_bow, ytrain_bow = smote.fit_resample(xtrain_bow, ytrain)"]},{"cell_type":"markdown","metadata":{"id":"NvsLL6meDkC6"},"source":["## 5.3 TF-IDF"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Gd5UzFciB1A9"},"outputs":[],"source":["# initialize tfidf vectorizer\n","word_tfidf = TfidfVectorizer()\n","\n","# transform xtrain and xval\n","xtrain_word = word_tfidf.fit_transform(xtrain).toarray()\n","xval_word = word_tfidf.transform(xval)\n","\n","# SMOTE\n","# initialize SMOTE\n","smote = SMOTE()\n","\n","# fit and resample\n","xtrain_word, ytrain_word = smote.fit_resample(xtrain_word, ytrain)"]},{"cell_type":"markdown","metadata":{"id":"BwLFxcrQDkC6"},"source":["## 5.4 Word Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1683472854885,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"lpSJgbWlDkC6"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"PbyGM63rDkC6"},"source":["# 6. Modelling"]},{"cell_type":"markdown","metadata":{"id":"QBVZXN22Hrba"},"source":["## 6.1 Modelling Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":438,"status":"ok","timestamp":1683474457108,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"cafKjEntHoj3"},"outputs":[],"source":["def multiple_roc_auc(classifiers, xtrain, xval, ytrain, yval):\n","    '''\n","    Plots ROC/AUC curves for multiple classifiers.\n","    Input: classifiers (dict), xtrain, ytrain, xval, yval\n","    Output: ROC/AUC curves plot\n","    '''\n","\n","    fig, ax = plt.subplots(1, figsize=(15, 10))\n","    for name, clf in classifiers.items():\n","        clf.fit(xtrain, ytrain)\n","        RocCurveDisplay.from_estimator(clf, xval, yval, ax=ax, name=name)\n","    ax.set_title('Receiver Operating Characteristic (ROC)')\n","    ax.plot([0,1], [0,1], linestyle='--')\n","    return plt.show()\n","\n","def learning_curves(estimator, x, y, cv=10, scoring='f1'):\n","    '''\n","    Plots learning curve for different training set sizes\n","    Input: estimator, x, y, (optional: cv, scoring)\n","    Output: learning curve plot\n","    '''\n","\n","    train_sizes, train_scores, validation_scores = learning_curve(estimator, x, y, cv=cv, scoring=scoring, train_sizes=np.arange(.05,1,.05))\n","    train_mean, test_mean, train_std, test_std = np.mean(train_scores, axis=1), np.mean(validation_scores, axis=1), np.std(train_scores, axis=1), np.std(validation_scores, axis=1)\n","\n","    plt.subplots(1, figsize=(10,10))\n","    plt.plot(train_sizes, train_mean, color='salmon',  label='Training score', marker = 'o')\n","    plt.plot(train_sizes, test_mean, color='olive', label='Cross-validation score', marker = 's')\n","    plt.title('Learning Curve')\n","    plt.xlabel('Training Set Size')\n","    plt.ylabel(f'{scoring.upper()} Score')\n","    plt.legend(loc='best')\n","    return plt.show()"]},{"cell_type":"markdown","metadata":{"id":"AL1IZqSoDkC6"},"source":["## 6.2 Baseline Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ncxnu9JyIhyL"},"outputs":[],"source":["# # classifiers to check\n","# classifiers = {\n","#                 'K-Nearest Neighbors': KNeighborsClassifier(),\n","#                 'Logistic Regression': LogisticRegression(),\n","#                 'Random Forest': RandomForestClassifier()\n","#                 }\n","\n","# multiple_roc_auc(classifiers, xtrain_word, xval_word, ytrain, yval)"]},{"cell_type":"markdown","metadata":{"id":"1AvqxlPDDkC7"},"source":["### 6.2.1 Logistic Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ksMGYXI92q2i"},"outputs":[],"source":["# Bag-of-Words\n","\n","logreg = LogisticRegression(n_jobs=-1)\n","# fit model on training data\n","logreg.fit(xtrain_bow, ytrain_bow)\n","# make predictions on validation data\n","ypred = logreg.predict(xval_bow)\n","print(classification_report(yval, ypred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LWt_bBmoDkC7"},"outputs":[],"source":["# TF-IDF\n","\n","logreg = LogisticRegression(n_jobs=-1)\n","# fit model on training data\n","logreg.fit(xtrain_word, ytrain_word)\n","# make predictions on validation data\n","ypred = logreg.predict(xval_word)\n","print(classification_report(yval, ypred))"]},{"cell_type":"markdown","metadata":{"id":"YTwe2XxkDkC7"},"source":["### 6.2.2 RandomForest"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZYPvkLGU2xCC"},"outputs":[],"source":["# Bag-of-Words\n","\n","rf = RandomForestClassifier(n_jobs=-1)\n","# fit model on training data\n","rf.fit(xtrain_bow, ytrain_bow)\n","# make predictions on validation data\n","ypred = rf.predict(xval_bow)\n","print(classification_report(yval, ypred))"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"LTu5iVEZDkC7"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.93      0.89      0.91      2710\n","           1       0.75      0.83      0.79      1039\n","\n","    accuracy                           0.88      3749\n","   macro avg       0.84      0.86      0.85      3749\n","weighted avg       0.88      0.88      0.88      3749\n","\n"]}],"source":["# TF-IDF\n","\n","rf = RandomForestClassifier(n_jobs=-1)\n","# fit model on training data\n","rf.fit(xtrain_word, ytrain_word)\n","# make predictions on validation data\n","ypred = rf.predict(xval_word)\n","# print classification report\n","print(classification_report(yval, ypred))"]},{"cell_type":"markdown","metadata":{"id":"6vRRowa6DkC7"},"source":["## 6.3 Neural Networks"]},{"cell_type":"markdown","metadata":{"id":"QNfbdGqrDkC7"},"source":["### 6.3.1 Recurrent Neural Networks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DDZ_IBv6DkC7"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"_G4LDPF6DkC7"},"source":["### 6.3.2 LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R7LhupW4DkC7"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"UikFpj-XDkC8"},"source":["## 6.4 Transfer Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ubYgcyKc7pz"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["Y-M1169-7Fkt","mk5tfM-27Fky","xqFhw_b3ohpN","6fSUIrfC7Fkz","Bt9h3ODfDkC4","6tyRQu25EJQi","UgW3LtGkEJQj","QBVZXN22Hrba"],"gpuType":"V100","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"nova","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
