{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Y-M1169-7Fkt"},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\lukas\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\lukas\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["# basics\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# preprocessing\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import SnowballStemmer\n","from nltk.stem.wordnet import WordNetLemmatizer\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# sentiment analysis (vaderSentiment)\n","try:\n","    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","except:\n","    !pip install vaderSentiment\n","    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n","\n","# # pycld2\n","# try:\n","#   import pycld2 as cld2\n","# except:\n","#   !pip install pycld2\n","#   import pycld2 as cld2\n","\n","# # deep_translator\n","# try:\n","#   from deep_translator import GoogleTranslator\n","# except:\n","#   !pip install deep-translator\n","#   from deep_translator import GoogleTranslator\n","\n","# sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mk5tfM-27Fky"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18584,"status":"ok","timestamp":1683299930675,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"2mDQggAH7ehv","outputId":"354444a3-dc41-467e-b146-9fbc41892a48"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# %cd '/content/drive/MyDrive/TextMiningProject'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":60581,"status":"ok","timestamp":1683299991253,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"Kma2qam77Fky"},"outputs":[],"source":["train = pd.read_excel('Data/train.xlsx', index_col='index')\n","train_reviews = pd.read_excel('Data/train_reviews.xlsx', index_col='index')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"xqFhw_b3ohpN"},"source":["# 1. Exploratory Data Analysis\n","\n","- on whole trainset (maybe train-test split has to be done before exploration)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IqVfhupcqkRs"},"source":["## 1.1 train.xlsx"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1683299991253,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"M_DwjhApomC5"},"outputs":[],"source":["# define dataframe variable\n","dataframe = train.copy()\n","dataframe = dataframe.reset_index()\n","\n","# define target feature\n","target_feature = 'unlisted'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1683299991253,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"37ML7cc8p_5w","outputId":"9350ec09-ed92-4f3e-90f2-a25492dc66a0"},"outputs":[],"source":["# display head & tail\n","dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1683299991254,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"h19JSim7qEla","outputId":"6ac796f0-dff3-4555-d26d-6e78126e01da"},"outputs":[],"source":["# data types\n","print('Data Types:', '\\n')\n","dataframe.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1683299991254,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"msLG5vulqRKE","outputId":"92146f83-ba2a-4128-de18-a84d679a0f2b"},"outputs":[],"source":["# missing values\n","print('Missing Values:', '\\n')\n","pd.concat([dataframe.isnull().sum(), dataframe.eq('').sum()], keys=['Nulls','Empty Strings'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1683299991254,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"gmN1LvMMqUuA","outputId":"1ed3e188-2b97-40b0-8871-144958cda266"},"outputs":[],"source":["# duplicated rows\n","print('Duplicated Rows:', '\\n')\n","dataframe.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":552,"status":"ok","timestamp":1683299991790,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"_dBlN3rpqYx5","outputId":"032a79ac-97dd-43a7-e5ed-4d69c005078a"},"outputs":[],"source":["# descriptive statistics\n","print('Descriptive Statistics:', '\\n')\n","dataframe.describe(include='all').T"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1683299991791,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"yYzwQ0vSrocf","outputId":"cf9165d6-7bf6-401f-dfe3-eea09a5514df"},"outputs":[],"source":["# check for imbalance\n","# Count the number of instances for each target value\n","target_counts = dataframe[target_feature].value_counts()\n","\n","# Create a pie chart\n","plt.pie(target_counts, labels=target_counts.index, autopct='%1.1f%%')\n","plt.axis('equal')\n","plt.title('Target Imbalance Check')\n","plt.legend(labels=['listed', 'unlisted'])\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cew43zt9qr0u"},"source":["## 1.2 train_reviews.xlsx"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1683299991791,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"FAknBDRgqx-6"},"outputs":[],"source":["# define dataframe variable\n","dataframe = train_reviews.copy()\n","dataframe = dataframe.reset_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1683299991791,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"Q2dt7knGq5j5","outputId":"4033ccaf-988c-4290-a2ee-06c49461d9e3"},"outputs":[],"source":["# display head & tail\n","dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1683299991791,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"bxAfkveHrBSn","outputId":"b28dff58-4dd9-4e46-bda7-a69d59e8ba50"},"outputs":[],"source":["# data types\n","print('Data Types:', '\\n')\n","dataframe.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":926,"status":"ok","timestamp":1683299992705,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"a_zihtl1rB3b","outputId":"638bd3f7-5554-4b7b-c058-e3629d030abb"},"outputs":[],"source":["# missing values\n","print('Missing Values:', '\\n')\n","pd.concat([dataframe.isnull().sum(), dataframe.eq('').sum()], keys=['Nulls','Empty Strings'], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683299992706,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"CJ2VLWzPrb7J","outputId":"c2e38cff-9dae-41dd-df2a-183d802f16c6"},"outputs":[],"source":["# duplicated rows\n","print('Duplicated Rows:', '\\n')\n","dataframe.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1683299993045,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"NtE_LddmriGV","outputId":"d49a8d24-14e1-44f6-bad3-a89bff3c952e"},"outputs":[],"source":["# descriptive statistics\n","print('Descriptive Statistics:', '\\n')\n","dataframe.describe(include='all').T"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6fSUIrfC7Fkz"},"source":["# 2. Preprocessing\n","\n","- lemmatizing based on detected language"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_UTeUgCKDkC3"},"source":["## 2.1 Regex Patterns"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683299993045,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"LvmUJ6zNDkC3"},"outputs":[],"source":["regex_patterns = {\n","    # manually identified patterns\n","    r'_x005f_x000d_':               ' ',\n","    r'_x000d_':                     ' ',\n","    r'm2':                          'squaremeter',\n","    r'sm':                          'squaremeter',\n","    r'sqm':                         'squaremeter',\n","    r'm²':                          'squaremeter',\n","    r'license[ number]+[0-9a-z]+':  ' ',\n","    r'(\\\\b\\\\w)\\\\1+\\\\b':             ' ',\n","\n","    # basic patterns\n","    # remove url\n","    r'http\\S+':                     ' ',\n","    # remove html tags\n","    r'<.*?>':                       ' ',\n","    # remove punctuation\n","    r'[^\\w\\s]':                     ' ',\n","    # remove numbers\n","    r'\\d+':                         ' ',\n","    # remove multiple whitespace\n","    r'\\s+':                         ' ',\n","    # remove newline\n","    r'\\n':                          ' '\n","}"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"vGCR06nSDkC3"},"source":["## 2.2 Preprocessing Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1683299993046,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"lK8IC2WW7Fkz"},"outputs":[],"source":["def text_preprocessing(dataframe):\n","  '''\n","  Preprocessing Pipeline\n","  Input: dataframe\n","  Output: transformed dataframe\n","  '''\n","\n","  stop = set(stopwords.words('english'))\n","  lemma = WordNetLemmatizer()\n","\n","  # lowercase non-numeric features \n","  categorical_features = list(dataframe.select_dtypes(exclude = np.number).columns)\n","  for col in categorical_features:\n","      dataframe[col] = dataframe[col].apply(lambda x: x.lower() if type(x) == str else '')\n","    \n","  # drop duplicates\n","  dataframe = dataframe.reset_index()\n","  dataframe = dataframe.drop_duplicates()\n","\n","  # fill empty cells\n","  for col in categorical_features:\n","    dataframe[col] = dataframe[col].fillna('')\n","\n","  # re.sub regex patterns (dictionary defined in the cell above)\n","  for col in categorical_features:\n","    for key, value in regex_patterns.items(): \n","          dataframe[col] = dataframe[col].apply(lambda x: re.sub(key,value,x))\n","\n","  # remove stopwords and lemmatize words\n","  for col in categorical_features:\n","      dataframe[col] = dataframe[col].apply(lambda x: ' '.join([lemma.lemmatize(word) for word in x.split() if word not in stop]))\n","\n","  # detect language\n","  for col in categorical_features:\n","      new_col = col + '_lang'\n","      dataframe[new_col] = dataframe[col].apply(lambda x: cld2.detect(x)[-1][0][0] if len(x) < 5000 else 'text has more than 5k characters')\n","\n","  return dataframe"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0Ltd5aUbDkC4"},"source":["## 2.3 Apply Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10727,"status":"ok","timestamp":1683300003765,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"g4_QuJANtwb5"},"outputs":[],"source":["train_preprocessed = train.copy()\n","train_preprocessed = text_preprocessing(train_preprocessed)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":129816,"status":"ok","timestamp":1683300133579,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"Gkht-0VLu0c0"},"outputs":[],"source":["train_reviews_preprocessed = train_reviews.copy()\n","train_reviews_preprocessed = text_preprocessing(train_reviews_preprocessed)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Bt9h3ODfDkC4"},"source":["# 3. Feature Engineering (Sentiment Analysis on Comments)\n","\n","- so far only sentiment analysis for englisch comments"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1683300133580,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"sHpdH-SFDkC4"},"outputs":[],"source":["def sentiment_analysis(dataframe, column='comments', language_column='comments_lang', compound=False):\n","    '''\n","    Sentiment analysis using vaderSentiment\n","    Input: dataframe\n","    Output: dataframe with sentiment column\n","    '''\n","    new_column = column + '_sentiment'\n","    sia = SentimentIntensityAnalyzer()\n","\n","    # return sentiment label with highest score\n","    if compound is False:\n","      dataframe[new_column] = dataframe[column].apply(lambda x: sia.polarity_scores(x))\n","      dataframe[new_column] = dataframe[new_column].apply(lambda x: {key:val for key,val in x.items() if key != 'compound'})\n","      dataframe[new_column] = dataframe[new_column].apply(lambda x: max(x, key=x.get))\n","      # set empty string comments from 'neg' (negative) to 'neu' (neutral)\n","      dataframe[new_column] = ['neu' if y == '' else x for x,y in zip(dataframe[new_column], dataframe[column])]\n","      # exception for comments which are not in english\n","      dataframe[new_column] = ['neu' if y != 'ENGLISH' else x for x,y in zip(dataframe[new_column], dataframe[language_column])]\n","\n","    # compound score is a combined score that ranges from -1 to 1\n","    # higher values indicating more positive sentiment\n","    elif compound is True:\n","      dataframe[new_column] = dataframe[column].apply(lambda x: sia.polarity_scores(x)['compound'])\n","      # exception for comments which are not in english\n","      dataframe[new_column] = [0 if y != 'ENGLISH' else x for x,y in zip(dataframe[new_column], dataframe[language_column])]\n","\n","    return dataframe"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":177890,"status":"ok","timestamp":1683300311459,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"otOcRcemDkC4"},"outputs":[],"source":["train_reviews_sentiment = train_reviews_preprocessed.copy()\n","train_reviews_sentiment = sentiment_analysis(train_reviews_sentiment)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":183401,"status":"ok","timestamp":1683300494848,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"UQXXWGAyDkC5"},"outputs":[],"source":["train_reviews_sentiment_compound = train_reviews_preprocessed.copy()\n","train_reviews_sentiment_compound = sentiment_analysis(train_reviews_sentiment_compound, compound=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":17559,"status":"ok","timestamp":1683300533084,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"Uz-1qjnaDkC5"},"outputs":[],"source":["train_preprocessed.to_csv('Data/train_preprocessed.csv', index=False)\n","train_reviews_sentiment.to_csv('Data/train_reviews_sentiment.csv', index=False)\n","train_reviews_sentiment_compound.to_csv('Data/train_reviews_sentiment_compound.csv', index=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 4. Train-Test Split"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4152,"status":"ok","timestamp":1683300727259,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"npfV6P3ADkC5"},"outputs":[],"source":["# read in preprocessed data (so preprocessing doesn't have to be done again)\n","# keep_default_na=False to prevent empty strings from being read in as NaN\n","train_preprocessed = pd.read_csv('Data/train_preprocessed.csv', keep_default_na=False)\n","train_reviews_sentiment = pd.read_csv('Data/train_reviews_sentiment.csv', keep_default_na=False)\n","train_reviews_sentiment_compound = pd.read_csv('Data/train_reviews_sentiment_compound.csv', keep_default_na=False)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 5.1 Combine Text"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683300494851,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"X3tgPHaJDkC6"},"outputs":[],"source":["# combine all text for an airbnb and create one BoW per airbnb\n","\n","def combine_text(dataframe1=train_preprocessed, dataframe2=train_reviews_sentiment):\n","    '''\n","    Combine all text for an airbnb\n","    Input: dataframe1 (train_preprocessed), dataframe2 (train_reviews_sentiment)\n","    Output: combined dataframe\n","    Output format: 'unlisted', 'text'\n","    '''\n","    # prepare dataframe1\n","    # combine description and host_about\n","    dataframe1['text'] = [x + ' ' + y for x,y in zip(dataframe1['description'], dataframe1['host_about'])]\n","    # drop description, host_about, description_lang, host_about_lang\n","    dataframe1 = dataframe1.drop(['description', 'host_about', 'description_lang', 'host_about_lang'], axis=1)\n","\n","    # prepare dataframe2\n","    # combine all text comments for an index\n","    aggregated_comments = pd.DataFrame(dataframe2.groupby('index')['comments'].agg(lambda x: ' '.join(x))).reset_index()\n","    # combine all sentiment labels for an index\n","    aggregated_sentiment_label = pd.DataFrame(dataframe2.groupby('index')['comments_sentiment'].agg(lambda x: ' '.join(x))).reset_index()\n","    # add sentiment_labels to aggregated_comments\n","    aggregated_comments['comments'] = [x + ' ' + y for x,y in zip(aggregated_comments['comments'], aggregated_sentiment_label['comments_sentiment'])]\n","    dataframe2 = aggregated_comments\n","\n","    # merge dataframe1 and dataframe2 on index\n","    combined = pd.merge(dataframe1, dataframe2, on='index', how='left')\n","    # fill empty cells for missing comments\n","    combined = combined.fillna('')\n","    # combine all text for an airbnb\n","    combined['text'] = [x + ' ' + y for x,y in zip(combined['text'], combined['comments'])]\n","    # drop comments\n","    combined = combined.drop(['comments'], axis=1)\n","    # set index to 'index' or airbnb id\n","    combined = combined.set_index('index')\n","\n","    return combined"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>unlisted</th>\n","      <th>text</th>\n","    </tr>\n","    <tr>\n","      <th>index</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>shared mixed room hostel shared bathroom locat...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>meu espaço fica perto de parque eduardo vii sa...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>trafaria house cozy familiar villa facility ne...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       unlisted                                               text\n","index                                                             \n","1             0  shared mixed room hostel shared bathroom locat...\n","2             1  meu espaço fica perto de parque eduardo vii sa...\n","3             1  trafaria house cozy familiar villa facility ne..."]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["train_preprocessed_to_combine, train_reviews_sentiment_to_combine = train_preprocessed.copy(), train_reviews_sentiment.copy()\n","train_combined = combine_text(train_preprocessed_to_combine, train_reviews_sentiment_to_combine)\n","train_combined.head(3)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 5.2 Train-Test Split"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["x, y = train_combined['text'], train_combined['unlisted']\n","xtrain, xval, ytrain, yval = train_test_split(x, y, test_size=0.3, stratify=y, random_state=420)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"sNa7WxNRn3QF"},"source":["# 5. Encoding"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"5TqO0FNxDkC6"},"source":["## 5.2 Bag-of-Words"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NvsLL6meDkC6"},"source":["## 5.3 TF-IDF"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683300494851,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"Gd5UzFciB1A9"},"outputs":[],"source":["# initialize tfidf vectorizer\n","word_tfidf = TfidfVectorizer(max_df=0.8, ngram_range=(1, 1))\n","\n","# transform xtrain and xval\n","xtrain_word = word_tfidf.fit_transform(xtrain)\n","xval_word = word_tfidf.transform(xval)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BwLFxcrQDkC6"},"source":["## 5.4 Word Embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683300494851,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"lpSJgbWlDkC6"},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PbyGM63rDkC6"},"source":["# 6. Modelling"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"AL1IZqSoDkC6"},"source":["## 6.1 Baseline Model"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1AvqxlPDDkC7"},"source":["### 6.1.1 Logistic Regression"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683300494851,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"LWt_bBmoDkC7"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.92      0.91      0.91      2710\n","           1       0.77      0.79      0.78      1039\n","\n","    accuracy                           0.88      3749\n","   macro avg       0.85      0.85      0.85      3749\n","weighted avg       0.88      0.88      0.88      3749\n","\n"]}],"source":["logreg = LogisticRegression()\n","# fit model on training data\n","logreg.fit(xtrain_word, ytrain)\n","# make predictions on validation data\n","ypred = logreg.predict(xval_word)\n","print(classification_report(yval, ypred))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"YTwe2XxkDkC7"},"source":["### 6.1.2 RandomForest"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683300494851,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"LTu5iVEZDkC7"},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.93      0.91      0.92      2710\n","           1       0.78      0.81      0.79      1039\n","\n","    accuracy                           0.88      3749\n","   macro avg       0.85      0.86      0.86      3749\n","weighted avg       0.89      0.88      0.88      3749\n","\n"]}],"source":["rf = RandomForestClassifier()\n","# fit model on training data\n","rf.fit(xtrain_word, ytrain)\n","# make predictions on validation data\n","ypred = rf.predict(xval_word)\n","# print classification report\n","print(classification_report(yval, ypred))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"6vRRowa6DkC7"},"source":["## 6.2 Neural Networks"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QNfbdGqrDkC7"},"source":["### 6.2.1 Recurrent Neural Networks"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1683300494852,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"DDZ_IBv6DkC7"},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"_G4LDPF6DkC7"},"source":["### 6.2.2 LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1683300494852,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"R7LhupW4DkC7"},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"UikFpj-XDkC8"},"source":["## 6.3 Transfer Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1683300494852,"user":{"displayName":"Lukas Stark","userId":"11679398301147369299"},"user_tz":-60},"id":"2ubYgcyKc7pz"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["Y-M1169-7Fkt","mk5tfM-27Fky","xqFhw_b3ohpN","6fSUIrfC7Fkz"],"gpuType":"V100","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"nova","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
